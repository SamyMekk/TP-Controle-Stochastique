{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0436e0c9",
   "metadata": {},
   "source": [
    "<h1><center> TP n°2 : RL in Continuous Time  </center></h1>\n",
    "\n",
    "\n",
    "<h5> Welcome to the TP n°2 of the course Apprentissage automatique et contrôle stochastique  which will focus on RL in continuous time ! </h5>\n",
    "\n",
    "\n",
    "<h2> Summary : </h2>\n",
    "\n",
    "- [An overview of the TP](#introduction)\n",
    "- [Policy Gradient Methods](#policy-gradient-methods-in-continuous-time)\n",
    "  - [Actor Critic Algorithms](#policy-gradient-actor-critic-algorithms)\n",
    "  - [The Linear Quadratic case](#policy-gradient-LQ-case)\n",
    "    - [Mean Variance Portfolio Selection](#policy-gradient-Mean-Variance)\n",
    "    - [Optimal Trading](#policy-gradient-Optimal-Trading)\n",
    "- [Q-Learning in continuous time](#q-learning-in-continuous-time)\n",
    "  - [Actor Critic Algorithms](#q-learning-actor-critic-algorithms)\n",
    "  - [The Linear Quadratic case](#q-learning-LQ-case)\n",
    "    - [Mean Variance Portfolio Selection](#q-learning-Mean-Variance)\n",
    "    - [Optimal Trading](#q-learning-Optimal-Trading)\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc8288",
   "metadata": {},
   "source": [
    "<a id=introduction></a>\n",
    "<h2> <center> Introduction  </center> </h2>\n",
    "\n",
    "Ce TP a pour but d'illustrer les méthodes numériques du RL en temps continu vus pendant le cours. Nous allons illustrer à la fois les méthodes de [Policy Gradients](#policy-gradient-methods-in-continuous-time) et de [Q-Learning](#q-learning-in-continuous-time) dans le cas d'un problème de contrôle Linéaire Quadratique où l'on va pouvoir vérifier les implémentations numériques avec des résultats théoriques.\n",
    "\n",
    "**Note : Ce TP n'est pas prévu pour être finissable en 3h, le but étant pour vous de pouvoir à minima d'implémenter une des 2 méthodes, que ce soit la Policy Gradient ou le Q-learning.**\n",
    "\n",
    "\n",
    "On rappelle les principaux résultats ci-dessous pour le problème de contrôle : Le cours est également proposé \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "V^{\\pi_{\\theta}}(t,x) = \\mathbb{E}_{\\pi^{\\theta}} [ \\int_{t}^{T} f(X_s,\\alpha_s) - \\lambda log (\\pi_{\\theta})(s,X_s,\\alpha_s) + g(X_T) | X_t= x]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c9a161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fe4d32",
   "metadata": {},
   "source": [
    "<a id=policy-gradient-methods-in-continuous-time></a>\n",
    "<h2> <center> Policy gradient methods in continous time :  </center> </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87354eef",
   "metadata": {},
   "source": [
    "<img src=\"images/AC-offline.png\" alt=\"Test\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850aa672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c5e4b0f",
   "metadata": {},
   "source": [
    "<img src=\"images/AC-online.png\" alt=\"Test\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7537ae1",
   "metadata": {},
   "source": [
    "<a id=policy-gradient-LQ-case></a>\n",
    "<h3>  Linear Quadratic Case in Policy Gradients :  </h3>\n",
    "\n",
    "\n",
    "On va implémenter les cas linéaire quadratique c'est à dire lorsque :\n",
    "\n",
    "- les coefficients $b$ et $\\sigma$ sont linéaires en $x$ et $a$.\n",
    "- les rewards $f$ et $g$ sont quadratiques en $x$ et $a$. Typiquement, on a : \n",
    "\n",
    "\n",
    "On va tester 2 problèmes typiques en finance :\n",
    "\n",
    "\n",
    "- **Mean Variance Portfolio Selection**\n",
    "- **Optimal Trading** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f6a72",
   "metadata": {},
   "source": [
    "<a id=policy-gradient-Mean-Variance></a>\n",
    "<h4>  Mean Variance Portfolio Selection :  </h4>\n",
    "\n",
    "The model is given by the following :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "dX_s = \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268b80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3dc2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9ab7989",
   "metadata": {},
   "source": [
    "<h5> Sanity check for optimal control $\\alpha^{*}_t$ </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa074f3",
   "metadata": {},
   "source": [
    "<a id=policy-gradient-Optimal-Trading></a>\n",
    "<h4>  Optimal Trading :  </h4>\n",
    "\n",
    "\n",
    "The model is given by the following :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "dX_s = \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd14aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Implement the previous formulas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3ee95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee5c2ba9",
   "metadata": {},
   "source": [
    "<h5> Sanity check for optimal control $\\alpha^{*}_t$ </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56396e1c",
   "metadata": {},
   "source": [
    "<a id=q-learning-in-continuous-time></a>\n",
    "<h2> <center> Q-learning in continous time :  </center> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0416bd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61372eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88bf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff02c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3fef6e4",
   "metadata": {},
   "source": [
    "<a id=references></a>\n",
    "<h2> <center> References :  </center> </h2>\n",
    "\n",
    "\n",
    "$\\bullet$ TBD\n",
    "\n",
    "$\\bullet$ TBD\n",
    "\n",
    "$\\bullet$ TBD\n",
    "\n",
    "$\\bullet$ TBD\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ec8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppStatApp_TP2",
   "language": "python",
   "name": "appstatapp_tp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
